{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3XlHpRaMAoAs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jO0eGrVRN6kF"
   },
   "outputs": [],
   "source": [
    "train_data_path = r\"F:\\PAST\\HUST\\IT-E10\\Introduction to AI\\Intro2AI\\train\"\n",
    "train_label_path = r\"F:\\PAST\\HUST\\IT-E10\\Introduction to AI\\Intro2AI\\train_label.csv\"\n",
    "train_labels = pd.read_csv(train_label_path)\n",
    "train_dict = train_labels.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DytOtNlzCxGZ"
   },
   "outputs": [],
   "source": [
    "class TrainImageDataset(Dataset):\n",
    "    def __init__(self, data_dict, input_path, transform=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.input_path = input_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dict)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_dict[idx]['image_name']\n",
    "        label = self.data_dict[idx]['label']\n",
    "\n",
    "        img_path = os.path.join(self.input_path, img_name)\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Dpk-aICfDQPv"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tKqw7lkSDS3i"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_dataset = TrainImageDataset(data_dict=train_dict, input_path=train_data_path, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Gd110z4AbXnm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")  \n",
    "NUM_CLASSES = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ARSoVjF0xDrv"
   },
   "outputs": [],
   "source": [
    "# !!! Do not change anything of this cell !!!\n",
    "from torch import Tensor\n",
    "from typing import Type\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        stride: int = 1,\n",
    "        expansion: int = 1,\n",
    "        downsample: nn.Module = None,\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.expansion = expansion\n",
    "        self.downsample = downsample\n",
    "        self.conv1_layer = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2_layer = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels * self.expansion,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1_layer(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2_layer(out)\n",
    "        out = self.batch_norm2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNN(nn.Module): #ResNet18\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[BasicBlock],\n",
    "        img_channels: int = 3,\n",
    "        num_classes: int = 10,\n",
    "    ) -> None:\n",
    "        super(CNN, self).__init__()\n",
    "        layers = [2, 2, 2, 2]\n",
    "        self.expansion = 1\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv_layer = nn.Conv2d(\n",
    "            in_channels=img_channels,\n",
    "            out_channels=self.in_channels,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool_layer = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer_1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer_2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer_3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer_4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool_layer = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_layer = nn.Linear(512 * self.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(\n",
    "        self, block: Type[BasicBlock], out_channels: int, blocks: int, stride: int = 1\n",
    "    ) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    out_channels * self.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.in_channels, out_channels, stride, self.expansion, downsample)\n",
    "        )\n",
    "        self.in_channels = out_channels * self.expansion\n",
    "\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(self.in_channels, out_channels, expansion=self.expansion)\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_layer(x)\n",
    "\n",
    "        c2 = self.layer_1(x)\n",
    "        c3 = self.layer_2(c2)\n",
    "        c4 = self.layer_3(c3)\n",
    "        c5 = self.layer_4(c4)\n",
    "\n",
    "        x = self.avgpool_layer(c5)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        # Channel Attention Components\n",
    "        self.ca_avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.ca_max = nn.AdaptiveMaxPool2d(1)\n",
    "        self.ca_fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.ca_relu = nn.ReLU()\n",
    "        self.ca_fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # Spatial Attention Components\n",
    "        self.sa_conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Channel Attention\n",
    "        avg_out = self.ca_fc2(self.ca_relu(self.ca_fc1(self.ca_avg(x))))\n",
    "        max_out = self.ca_fc2(self.ca_relu(self.ca_fc1(self.ca_max(x))))\n",
    "        x = x * self.sigmoid(avg_out + max_out)\n",
    "        # Spatial Attention\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        sa_map = self.sigmoid(self.sa_conv(torch.cat([avg_out, max_out], dim=1)))\n",
    "        return x * sa_map, sa_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryHead(nn.Module):\n",
    "    def __init__(self, in_channels=2048, num_classes=15):\n",
    "        super().__init__()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avgpool(x).flatten(1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridMaskSelector(nn.Module):\n",
    "    \"\"\"Responsible for logic: 3x3 Grid -> Select Best 2x2 Square -> Create Mask\"\"\"\n",
    "    def __init__(self, grid_size=3):\n",
    "        super().__init__()\n",
    "        self.grid_size = grid_size \n",
    "\n",
    "    def forward(self, attention_map, input_img):\n",
    "        B, _, H, W = input_img.shape\n",
    "        # 1. Downsample to grid\n",
    "        grid_att = F.adaptive_avg_pool2d(attention_map, (self.grid_size, self.grid_size))\n",
    "        \n",
    "        # 2. Find best 2x2 window\n",
    "        with torch.no_grad():\n",
    "            kernel = torch.ones((1, 1, 2, 2)).to(attention_map.device)\n",
    "            sum_att = F.conv2d(grid_att, kernel, stride=1).view(B, -1)\n",
    "            best_idx = torch.argmax(sum_att, dim=1)\n",
    "\n",
    "        # 3. Create Mask\n",
    "        mask = torch.zeros((B, 1, H, W)).to(input_img.device)\n",
    "        h_step, w_step = H // self.grid_size, W // self.grid_size\n",
    "        \n",
    "        for b in range(B):\n",
    "            idx = best_idx[b].item()\n",
    "            r, c = (idx // 2), (idx % 2)\n",
    "            mask[b, :, r*h_step:(r+2)*h_step, c*w_step:(c+2)*w_step] = 1.0\n",
    "\n",
    "        return input_img * (1 - mask), mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBackbone6Layers(CNN):\n",
    "    \"\"\"6-layer backbone built on top of CNN while preserving the original spatial/channel logic.\"\"\"\n",
    "    def __init__(self, block, img_channels=3):\n",
    "        # Reuse CNN stem and first 4 layers\n",
    "        super().__init__(block=block, img_channels=img_channels, num_classes=1)  # num_classes unused here\n",
    "        \n",
    "        # Force spatial size to 96x96 after the stem (replace prior maxpool effect)\n",
    "        self.force_spatial_96 = nn.AdaptiveAvgPool2d((96, 96))\n",
    "        \n",
    "        self.in_channels = 512  # state after layer_4 in the parent\n",
    "        self.layer_5 = self._make_layer(block, 1024, blocks=2, stride=2)  \n",
    "        self.layer_6 = self._make_layer(block, 2048, blocks=2, stride=2)  \n",
    "        \n",
    "        self._init_new_layers()\n",
    "        \n",
    "    def _init_new_layers(self):\n",
    "        # Initialize only the newly added layers to match prior custom init\n",
    "        for m in [self.layer_5, self.layer_6]:\n",
    "            for sub in m.modules():\n",
    "                if isinstance(sub, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(sub.weight, mode='fan_out', nonlinearity='relu')\n",
    "                elif isinstance(sub, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(sub.weight, 1)\n",
    "                    nn.init.constant_(sub.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Stem: conv7x7 stride2 -> BN/ReLU -> force to 96x96\n",
    "        x = self.conv_layer(x)            # [B, 64, 112, 112]\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.force_spatial_96(x)     # [B, 64, 96, 96]\n",
    "        \n",
    "        # Shared CNN layers 1-4\n",
    "        c1 = self.layer_1(x)              # [B, 64, 96, 96]\n",
    "        c2 = self.layer_2(c1)            # [B, 128, 48, 48]\n",
    "        c3 = self.layer_3(c2)            # [B, 256, 24, 24]\n",
    "        c4 = self.layer_4(c3)            # [B, 512, 12, 12]\n",
    "        \n",
    "        # Extra layers 5-6\n",
    "        c5 = self.layer_5(c4)            # [B, 1024, 6, 6]\n",
    "        c6 = self.layer_6(c5)            # [B, 2048, 3, 3]\n",
    "        \n",
    "        return [c1, c2, c3, c4], c6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(nn.Module):\n",
    "    def __init__(self, in_channels_list=[64, 128, 256, 512], out_channels=256):\n",
    "        super().__init__()\n",
    "        self.lateral = nn.ModuleList([nn.Conv2d(c, out_channels, 1) for c in in_channels_list])\n",
    "        self.smooth = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, features):\n",
    "        c2, c3, c4, c5 = features\n",
    "        # Top-down pathway\n",
    "        p5 = self.lateral[3](c5)\n",
    "        p4 = self.lateral[2](c4) + F.interpolate(p5, scale_factor=2)\n",
    "        p3 = self.lateral[1](c3) + F.interpolate(p4, scale_factor=2)\n",
    "        p2 = self.lateral[0](c2) + F.interpolate(p3, scale_factor=2)\n",
    "        return [p2, p3, p4, p5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedFC(nn.Module):\n",
    "    def __init__(self, in_channels=256, latent_dim=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder CNN: Nén FPN to nhất (96x96x256) xuống nhỏ hơn để vào FC\n",
    "        # Input: [B, 256, 96, 96]\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 256, kernel_size=3, stride=2, padding=1), # 96 -> 48\n",
    "            nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1), # 48 -> 24\n",
    "            nn.BatchNorm2d(512), nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1), # 24 -> 12\n",
    "            nn.BatchNorm2d(512), nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1), # 12 -> 6\n",
    "            nn.BatchNorm2d(512), nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # [512, 6, 6]\n",
    "        self.flatten_dim = 512 * 6 * 6 \n",
    "        \n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flatten_dim, 1024),\n",
    "            nn.BatchNorm1d(1024), nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim), nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        return self.fc_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainClassificationHead(nn.Module):\n",
    "    def __init__(self, latent_dim=512, num_classes=15):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructionHead(nn.Module):\n",
    "    def __init__(self, latent_dim=512):\n",
    "        super().__init__()\n",
    "        # Bung latent ra thành feature map để ConvTranspose\n",
    "        self.fc_expand = nn.Linear(latent_dim, 512 * 7 * 7) \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (512, 7, 7)),\n",
    "            # Upsample dần lên 224x224\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(), # -> 14\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(), # -> 28\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  nn.BatchNorm2d(64),  nn.ReLU(), # -> 56\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),   nn.BatchNorm2d(32),  nn.ReLU(), # -> 112\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1),    nn.Sigmoid()                    # -> 224\n",
    "        )\n",
    "\n",
    "    def forward(self, latent):\n",
    "        x = self.fc_expand(latent)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedAutoencoderSystem(nn.Module):\n",
    "    def __init__(self, num_classes=15):\n",
    "        super().__init__()\n",
    "        self.backbone = ResNetBackbone6Layers(BasicBlock)\n",
    "        \n",
    "        # 2. FPN & CBAM & Selector\n",
    "        self.fpn = FPN(in_channels_list=[64, 128, 256, 512], out_channels=256)\n",
    "        self.cbam = CBAM(in_planes=2048)\n",
    "        self.mask_selector = GridMaskSelector(grid_size=3)\n",
    "        \n",
    "        self.aux_head = AuxiliaryHead(in_channels=2048, num_classes=num_classes)\n",
    "        \n",
    "        # Shared FC: Nhận từ FPN (256 ch)\n",
    "        self.shared_fc = SharedFC(in_channels=256, latent_dim=512)\n",
    "        \n",
    "        # Main Head & Rec Head: Nhận từ Shared FC (Latent 512)\n",
    "        self.main_head = MainClassificationHead(latent_dim=512, num_classes=num_classes)\n",
    "        self.rec_head = ReconstructionHead(latent_dim=512)\n",
    "\n",
    "    def forward(self, x, training_mode=True):\n",
    "        # PHASE 1: CLEAN PASS\n",
    "        fpn_feats, final_feat = self.backbone(x) # fpn_feats = [c1, c2, c3, c4], final_feat = c6\n",
    "        # Tính toán FPN\n",
    "        fpn_outs = self.fpn(fpn_feats) \n",
    "        # fpn_outs[0] là lớp to nhất (tương ứng c1: 96x96)\n",
    "        largest_fpn_feat = fpn_outs[0] \n",
    "        # CBAM (cho Aux Loss & Mask Selector)\n",
    "        feat_att, att_map = self.cbam(final_feat)\n",
    "        \n",
    "        # --- Output 1: Aux Logits (Từ CBAM) ---\n",
    "        aux_logits = self.aux_head(feat_att)\n",
    "        # --- Output 2: Main Logits (Từ FPN to nhất -> Shared FC) ---\n",
    "        clean_latent = self.shared_fc(largest_fpn_feat)\n",
    "        main_logits = self.main_head(clean_latent)\n",
    "        \n",
    "        \n",
    "        # PHASE 2: MASKED PASS\n",
    "        rec_img, mask = None, None\n",
    "        if training_mode:\n",
    "            masked_x, mask = self.mask_selector(att_map.detach(), x) #detach() tạo nhánh mới, không truyền gradient\n",
    "            \n",
    "            # Cần chạy cả FPN vì SharedFC giờ đây yêu cầu output của FPN\n",
    "            m_fpn_feats, _ = self.backbone(masked_x)\n",
    "            m_fpn_outs = self.fpn(m_fpn_feats)\n",
    "            \n",
    "            # Lấy feature map to nhất của ảnh bị mask\n",
    "            m_largest_fpn_feat = m_fpn_outs[0] \n",
    "            \n",
    "            masked_latent = self.shared_fc(m_largest_fpn_feat)\n",
    "            rec_img = self.rec_head(masked_latent)\n",
    "            \n",
    "        return {\n",
    "            \"aux_logits\": aux_logits,\n",
    "            \"main_logits\": main_logits,\n",
    "            \"rec_img\": rec_img,\n",
    "            \"mask\": mask\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, device, lr=1e-3, save_interval=None, checkpoint_dir=\"checkpoints\"):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.device = device\n",
    "        \n",
    "        # Trọng số cho các loss (Hyperparameters)\n",
    "        self.lambda_aux = 0.4  # Aux loss thường có trọng số nhỏ hơn main\n",
    "        self.lambda_rec = 0.5  # Reconstruction loss\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        self.cls_criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Checkpoint settings\n",
    "        self.save_interval = save_interval  # Lưu mỗi N epochs, None = không tự động lưu\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        \n",
    "        # Tạo thư mục checkpoint nếu chưa có\n",
    "        if self.save_interval is not None:\n",
    "            os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        # Wandb initialization for experiment tracking\n",
    "        wandb.init(\n",
    "            project=\"pill-classification\",\n",
    "            name=\"masked-autoencoder-training\",\n",
    "            config={\n",
    "                \"learning_rate\": lr,\n",
    "                \"batch_size\": train_loader.batch_size,\n",
    "                \"lambda_aux\": self.lambda_aux,\n",
    "                \"lambda_rec\": self.lambda_rec,\n",
    "                \"optimizer\": \"Adam\",\n",
    "                \"loss_fn\": \"CrossEntropyLoss + MSE\"\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def find_latest_checkpoint(self):\n",
    "        \"\"\"Tìm checkpoint mới nhất (epoch lớn nhất) trong thư mục\"\"\"\n",
    "        if not os.path.exists(self.checkpoint_dir):\n",
    "            return None\n",
    "        \n",
    "        checkpoints = []\n",
    "        for file in os.listdir(self.checkpoint_dir):\n",
    "            if file.startswith(\"checkpoint_epoch_\") and file.endswith(\".pth\"):\n",
    "                try:\n",
    "                    # Extract epoch number from filename\n",
    "                    epoch_num = int(file.replace(\"checkpoint_epoch_\", \"\").replace(\".pth\", \"\"))\n",
    "                    checkpoints.append((epoch_num, os.path.join(self.checkpoint_dir, file)))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        \n",
    "        if not checkpoints:\n",
    "            return None\n",
    "        \n",
    "        # Trả về checkpoint với epoch lớn nhất\n",
    "        checkpoints.sort(key=lambda x: x[0], reverse=True)\n",
    "        return checkpoints[0][1]  # Return path của checkpoint mới nhất\n",
    "    \n",
    "    def masked_mse_loss(self, pred, target, mask):\n",
    "        loss = F.mse_loss(pred, target, reduction='none')\n",
    "        loss = loss * mask\n",
    "        return loss.sum() / (mask.sum() + 1e-6)\n",
    "\n",
    "    def train_one_epoch(self, epoch_index):\n",
    "        self.model.train()\n",
    "        running_loss_main = 0.0\n",
    "        running_loss_aux = 0.0\n",
    "        running_loss_rec = 0.0\n",
    "        running_loss_total = 0.0\n",
    "        \n",
    "        # Dùng tqdm để hiển thị progress bar đẹp hơn\n",
    "        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch_index}\")\n",
    "        \n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            outputs = self.model(images, training_mode=True)\n",
    "            \n",
    "            # 1. Main Classification Loss\n",
    "            loss_main = self.cls_criterion(outputs[\"main_logits\"], labels)\n",
    "            \n",
    "            # 2. Auxiliary Classification Loss\n",
    "            loss_aux = self.cls_criterion(outputs[\"aux_logits\"], labels)\n",
    "            \n",
    "            # 3. Reconstruction Loss\n",
    "            loss_rec = self.masked_mse_loss(outputs[\"rec_img\"], images, outputs[\"mask\"])\n",
    "            \n",
    "            # Tổng hợp Loss\n",
    "            total_loss = loss_main + (self.lambda_aux * loss_aux) + (self.lambda_rec * loss_rec)\n",
    "            \n",
    "            total_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Accumulate losses\n",
    "            running_loss_main += loss_main.item()\n",
    "            running_loss_aux += loss_aux.item()\n",
    "            running_loss_rec += loss_rec.item()\n",
    "            running_loss_total += total_loss.item()\n",
    "            \n",
    "            # Hiển thị chi tiết từng loss trên thanh tiến trình\n",
    "            pbar.set_postfix({\n",
    "                'T': f\"{total_loss.item():.2f}\", \n",
    "                'Main': f\"{loss_main.item():.2f}\",\n",
    "                'Aux': f\"{loss_aux.item():.2f}\",\n",
    "                'Rec': f\"{loss_rec.item():.2f}\"\n",
    "            })\n",
    "        \n",
    "        # Calculate average losses\n",
    "        num_batches = len(self.train_loader)\n",
    "        avg_loss_main = running_loss_main / num_batches\n",
    "        avg_loss_aux = running_loss_aux / num_batches\n",
    "        avg_loss_rec = running_loss_rec / num_batches\n",
    "        avg_loss_total = running_loss_total / num_batches\n",
    "        \n",
    "        # Log to wandb (4 loss metrics)\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch_index,\n",
    "            \"loss/main\": avg_loss_main,\n",
    "            \"loss/aux\": avg_loss_aux,\n",
    "            \"loss/rec\": avg_loss_rec,\n",
    "            \"loss/total\": avg_loss_total\n",
    "        })\n",
    "        \n",
    "        # Auto-save checkpoint nếu đến interval\n",
    "        if self.save_interval is not None and epoch_index % self.save_interval == 0:\n",
    "            checkpoint_path = os.path.join(self.checkpoint_dir, f\"checkpoint_epoch_{epoch_index}.pth\")\n",
    "            self.save_checkpoint(checkpoint_path, epoch_index, avg_loss_total)\n",
    "            print(f\"\\n✓ Saved checkpoint at epoch {epoch_index} to {checkpoint_path}\")\n",
    "            \n",
    "        return avg_loss_total\n",
    "\n",
    "    def save_checkpoint(self, path, epoch, loss):\n",
    "        \"\"\"Lưu checkpoint với thông tin đầy đủ\"\"\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, path)\n",
    "    \n",
    "    def load_checkpoint(self, path):\n",
    "        \"\"\"Load checkpoint để tiếp tục training\"\"\"\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        return checkpoint['epoch'], checkpoint['loss']\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"Lưu chỉ model state (final model)\"\"\"\n",
    "        torch.save(self.model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnguyenconghung1210\u001b[0m (\u001b[33mnguyenconghung1210-hanoi-university-of-science-and-techn\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\PAST\\HUST\\IT-E10\\Introduction to AI\\Intro2AI\\wandb\\run-20260105_161357-usmhft9h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nguyenconghung1210-hanoi-university-of-science-and-techn/pill-classification/runs/usmhft9h' target=\"_blank\">masked-autoencoder-training</a></strong> to <a href='https://wandb.ai/nguyenconghung1210-hanoi-university-of-science-and-techn/pill-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nguyenconghung1210-hanoi-university-of-science-and-techn/pill-classification' target=\"_blank\">https://wandb.ai/nguyenconghung1210-hanoi-university-of-science-and-techn/pill-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nguyenconghung1210-hanoi-university-of-science-and-techn/pill-classification/runs/usmhft9h' target=\"_blank\">https://wandb.ai/nguyenconghung1210-hanoi-university-of-science-and-techn/pill-classification/runs/usmhft9h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found checkpoint: model_checkpoints\\checkpoint_epoch_20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8984\\2300257109.py:144: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Resumed from epoch 20 (loss: 1.4923)\n",
      "→ Continue training from epoch 21\n",
      "\n",
      "Training from epoch 21 to 50...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1f82bb25f445ba8887738cbb124db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Avg Loss: 1.4060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da54d5e2bd9b40cab023866294fe858d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 22 to model_checkpoints\\checkpoint_epoch_22.pth\n",
      "Epoch 22/50 - Avg Loss: 1.3856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca426ac35204fb69e2f330d4a6a3f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Avg Loss: 1.3980\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27da4f9c74f04aac94290395a02377f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 24 to model_checkpoints\\checkpoint_epoch_24.pth\n",
      "Epoch 24/50 - Avg Loss: 1.3721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b119ab52655149a7a1294f51163e9b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Avg Loss: 1.3409\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddd9d5a206541cb9015bfcb6cb2da42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 26 to model_checkpoints\\checkpoint_epoch_26.pth\n",
      "Epoch 26/50 - Avg Loss: 1.3645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c83a43091041e68f8448c698282b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Avg Loss: 1.3513\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97152bca92a3466285609aa04ce9ebb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 28 to model_checkpoints\\checkpoint_epoch_28.pth\n",
      "Epoch 28/50 - Avg Loss: 1.2991\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8693a336734f7187ab0ef8aabbdea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Avg Loss: 1.2991\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e7df8cccd64782be83eeb48178b69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 30 to model_checkpoints\\checkpoint_epoch_30.pth\n",
      "Epoch 30/50 - Avg Loss: 1.3160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13000bad7539471fa8e37a07eb151700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Avg Loss: 1.2493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e28ca6049c4da8825ecd38358cbd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 32 to model_checkpoints\\checkpoint_epoch_32.pth\n",
      "Epoch 32/50 - Avg Loss: 1.2676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fdb135d28241a991a4c1f2dd8b74e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Avg Loss: 1.3224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f04454a534f48fda405b9832b69580a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 34 to model_checkpoints\\checkpoint_epoch_34.pth\n",
      "Epoch 34/50 - Avg Loss: 1.3237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b303a18ea74623b0dfa7960246da08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Avg Loss: 1.3670\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4dc2238e074eea806d1052fe27a646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 36 to model_checkpoints\\checkpoint_epoch_36.pth\n",
      "Epoch 36/50 - Avg Loss: 1.3574\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff3cff4b12744738ff8981b71943572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Avg Loss: 1.3368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f6820275614f19833e8556152cec62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 38 to model_checkpoints\\checkpoint_epoch_38.pth\n",
      "Epoch 38/50 - Avg Loss: 1.3344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2e328e6fba4426888fc2bededa21ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Avg Loss: 1.3082\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f606f4308e34644a5f7028ea8065cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 40 to model_checkpoints\\checkpoint_epoch_40.pth\n",
      "Epoch 40/50 - Avg Loss: 1.3139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96a6584a415496dbb24b7e205da5eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 - Avg Loss: 1.2980\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f32f71fd3cc48e88882c562b2daf231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 42 to model_checkpoints\\checkpoint_epoch_42.pth\n",
      "Epoch 42/50 - Avg Loss: 1.2554\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dad8caa3e849d897722d948430d57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 - Avg Loss: 1.2289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa3259edd544012ad254d477e47e7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 44 to model_checkpoints\\checkpoint_epoch_44.pth\n",
      "Epoch 44/50 - Avg Loss: 1.2081\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0086631c88c48d3af15461386500d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 - Avg Loss: 1.2304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e68520e19444b293c24900ac06a5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 46 to model_checkpoints\\checkpoint_epoch_46.pth\n",
      "Epoch 46/50 - Avg Loss: 1.2293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3628ebac13ac49f596deb403c94b321f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Avg Loss: 1.2378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b689de4422c94242a1590330e8dbaae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 48 to model_checkpoints\\checkpoint_epoch_48.pth\n",
      "Epoch 48/50 - Avg Loss: 1.2782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1175c9916514242b99bb813cf0ccebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Avg Loss: 1.2786\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f101fc5edb94eb4bcbf88fbc95a23c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved checkpoint at epoch 50 to model_checkpoints\\checkpoint_epoch_50.pth\n",
      "Epoch 50/50 - Avg Loss: 1.2480\n",
      "\n",
      "✓ Training Complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss/aux</td><td>▇▆▆▇▄█▅▄▄▆▃▄▇▆█▅▃▃▃▃▄▂▁▁▂▄▄▆▅▄</td></tr><tr><td>loss/main</td><td>▇▅▅▄▅▄▄▃▃▃▂▂▄▄▆██▆▅▆▄▃▂▂▂▁▁▃▄▃</td></tr><tr><td>loss/rec</td><td>▆▇█▆▅▆▆▄▅▅▄▄▃▄▄▄▄▅▄▄▄▃▃▁▂▂▂▂▂▁</td></tr><tr><td>loss/total</td><td>█▇█▇▆▇▆▄▄▅▂▃▅▅▇▆▆▅▅▅▄▃▂▁▂▂▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>loss/aux</td><td>0.09436</td></tr><tr><td>loss/main</td><td>0.06946</td></tr><tr><td>loss/rec</td><td>2.28167</td></tr><tr><td>loss/total</td><td>1.24804</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">masked-autoencoder-training</strong> at: <a href='https://wandb.ai/nguyenconghung1210-hanoi-university-of-science-and-techn/pill-classification/runs/usmhft9h' target=\"_blank\">https://wandb.ai/nguyenconghung1210-hanoi-university-of-science-and-techn/pill-classification/runs/usmhft9h</a><br> View project at: <a href='https://wandb.ai/nguyenconghung1210-hanoi-university-of-science-and-techn/pill-classification' target=\"_blank\">https://wandb.ai/nguyenconghung1210-hanoi-university-of-science-and-techn/pill-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20260105_161357-usmhft9h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_model = MaskedAutoencoderSystem(num_classes=NUM_CLASSES)\n",
    "\n",
    "# Khởi tạo Trainer với save_interval\n",
    "trainer = Trainer(\n",
    "    system_model, \n",
    "    train_dataloader, \n",
    "    device, \n",
    "    lr=1e-4,\n",
    "    save_interval=2,           # Lưu checkpoint mỗi 2 epochs\n",
    "    checkpoint_dir=\"model_checkpoints\"\n",
    ")\n",
    "\n",
    "# Tự động tìm và load checkpoint mới nhất (nếu có)\n",
    "latest_checkpoint = trainer.find_latest_checkpoint()\n",
    "start_epoch = 1\n",
    "\n",
    "if latest_checkpoint:\n",
    "    print(f\"Found checkpoint: {latest_checkpoint}\")\n",
    "    last_epoch, last_loss = trainer.load_checkpoint(latest_checkpoint)\n",
    "    start_epoch = last_epoch + 1\n",
    "    print(f\"✓ Resumed from epoch {last_epoch} (loss: {last_loss:.4f})\")\n",
    "    print(f\"→ Continue training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting from scratch.\")\n",
    "\n",
    "\n",
    "MAX_EPOCHS = 50\n",
    "\n",
    "if start_epoch > MAX_EPOCHS:\n",
    "    print(f\"Already trained to epoch {start_epoch-1}, target is {MAX_EPOCHS}. Nothing to do.\")\n",
    "    wandb.finish()\n",
    "else:\n",
    "    print(f\"\\nTraining from epoch {start_epoch} to {MAX_EPOCHS}...\")\n",
    "    for epoch in range(start_epoch, MAX_EPOCHS + 1):\n",
    "        avg_loss = trainer.train_one_epoch(epoch)\n",
    "        print(f\"Epoch {epoch}/{MAX_EPOCHS} - Avg Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Lưu model cuối cùng\n",
    "    trainer.save(\"masked_resnet_aux_model_final.pth\")\n",
    "    print(\"\\n✓ Training Complete!\")\n",
    "    \n",
    "    # Finish wandb tracking\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MyProjectPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "008fa5c5eb7b4f4bab3ca043b9163151": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "07412aef72be4cd89f28ef26be3c2066": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a0c49f320c9456d95c505ee3c6b8495": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88994cae248a4ad1ba69e8af090cf24c",
      "placeholder": "​",
      "style": "IPY_MODEL_d59b9412ff7a4844b0838970c2d7eea5",
      "value": "100%"
     }
    },
    "775d73702d0c4037986a9f59707e9022": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9b06a7f2a11484eb91dc427196c0b28",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_008fa5c5eb7b4f4bab3ca043b9163151",
      "value": 20
     }
    },
    "88994cae248a4ad1ba69e8af090cf24c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2d7ebf3941c4fd6b82c08cf73fa4127": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6a0c49f320c9456d95c505ee3c6b8495",
       "IPY_MODEL_775d73702d0c4037986a9f59707e9022",
       "IPY_MODEL_e332be71971943fab4de8e989b822810"
      ],
      "layout": "IPY_MODEL_c98eae38e2ea49bbbc17ac7cba5520a3"
     }
    },
    "c98eae38e2ea49bbbc17ac7cba5520a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cedb5e089445439ca60732cbe5a820db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d59b9412ff7a4844b0838970c2d7eea5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e332be71971943fab4de8e989b822810": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07412aef72be4cd89f28ef26be3c2066",
      "placeholder": "​",
      "style": "IPY_MODEL_cedb5e089445439ca60732cbe5a820db",
      "value": " 20/20 [02:10&lt;00:00,  6.53s/it]"
     }
    },
    "f9b06a7f2a11484eb91dc427196c0b28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
